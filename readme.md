# Personal AI

A desktop application that provides a chat interface for interacting with local AI models through Ollama.

## Overview

Personal AI is an Electron-based desktop application that connects to locally-running AI models via Ollama. Built with Next.js, TypeScript, and Tailwind CSS, it provides a modern, user-friendly interface for AI conversations with automatic setup and configuration.

## Key Features

- **Automatic Setup**: Detects and installs Ollama if not present
- **Model Management**: Automatically downloads the Qwen3 8B model (~4.7GB) with progress tracking
- **Chat Interface**: Clean, responsive UI for AI conversations
- **Real-time Streaming**: See AI responses as they're generated
- **Conversation History**: Save and manage your chat sessions
- **Cross-platform**: Works on macOS, Windows, and Linux

## Tech Stack

- **Electron** - Desktop application framework
- **Next.js** - React framework with TypeScript
- **Tailwind CSS** - Utility-first styling
- **Ollama** - Local LLM server
- **Qwen3 8B** - Language model

## Getting Started

### Prerequisites

- Node.js v18 or higher
- npm or yarn
- Ollama installed and running (with qwen3:8b model)

### Installation

```bash
# Install dependencies
npm install

# Run in development mode
npm run dev
```

This will start both the Next.js development server and the Electron app.

### Manual Setup

If you prefer to run components separately:

```bash
# Terminal 1: Start Next.js dev server
npm run dev:next

# Terminal 2: Start Electron (after Next.js is ready)
npm run dev:electron
```

### Building for Production

```bash
# Build the application
npm run build

# Run the production build
npm start
```

## Current Status

**Phase 1 Complete!** The basic chat interface is now functional. You can:
- Chat with Qwen3 8B model through Ollama
- See real-time streaming responses
- View conversation history in the current session

See [planning.md](planning.md) for the complete roadmap and upcoming features.

## Development Phases

1. **Phase 1**: Project Setup & Ollama Integration
2. **Phase 2**: Core Chat Interface
3. **Phase 3**: State Management & Persistence
4. **Phase 4**: Polish & Enhancement
5. **Phase 5**: Build & Distribution

## Documentation

- [Planning Document](planning.md) - Comprehensive project plan and architecture
- Development guide - Coming soon
- API documentation - Coming soon

## License

MIT

## Contributing

Contributions are welcome! Please read the contributing guidelines before getting started.
